{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(180000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154562/4197309928.py:12: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trials:  503\n",
      "all_trials:  (503, 1800, 16)\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "############# LOAD DATA AND VISUALIZE AVERAGES #################\n",
    "################################################################\n",
    "root_dir = '/home/cat/code/widefield_transformer/data/IA1'\n",
    "\n",
    "fname_trials = os.path.join(root_dir, 'trials.npy')\n",
    "d = np.load(fname_trials,\n",
    "            allow_pickle=True)\n",
    "\n",
    "\n",
    "#count the number of trials as the first axis of d\n",
    "n_trials = 0 \n",
    "for k in range(d.shape[0]):\n",
    "    n_trials += d[k].shape[0]\n",
    "print (\"# trials: \", n_trials)\n",
    "\n",
    "# make an array of all the trials to hold data as we loop\n",
    "all_trials = np.zeros((n_trials, d[0].shape[1], d[0].shape[2]), 'float32')\n",
    "\n",
    "#\n",
    "# loop over all the trials and populate the all_trials array\n",
    "\n",
    "ctr=0\n",
    "for k in range(d.shape[0]):\n",
    "    for p in range(d[k].shape[0]):\n",
    "        all_trials[ctr] = d[k][p]\n",
    "        ctr+=1\n",
    "\n",
    "#\n",
    "print (\"all_trials: \", all_trials.shape)\n",
    "\n",
    "# plot the last trial\n",
    "plt.figure()\n",
    "plt.title(\"Median neural activity for # trials \"\n",
    "          +str(all_trials.shape[0]) + \" from mouse IA1\")\n",
    "\n",
    "# make time vector t \n",
    "t = np.arange(all_trials.shape[1])/30.-30\n",
    "\n",
    "for area_id in range(16):\n",
    "    #plt.plot(all_trials[:,:,area_id].mean(0))\n",
    "    plt.plot(t, np.median(all_trials[:,:,area_id], 0),\n",
    "             label='brain area '+str(area_id),\n",
    "             alpha=.5   )\n",
    "    \n",
    "\n",
    "# plot vertical line at t = 0 with max and min y values\n",
    "plt.plot([0,0], [np.median(all_trials,0).min(), \n",
    "                 np.median(all_trials,0).max()], '--',c='black')\n",
    "\n",
    "# same for horizontal line at y=0\n",
    "plt.plot([t.min(), t.max()], [0,0], '--',c='black')\n",
    "\n",
    "#\n",
    "plt.xlabel('Time (sec)')\n",
    "\n",
    "#\n",
    "plt.ylabel(\"Neurala activity\")\n",
    "\n",
    "#\n",
    "plt.legend(fontsize=8, ncols=2)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding data into a transformer\n",
    "\n",
    "We are trying to feed the data into a transfomer model.\n",
    "\n",
    "The paradigm is roughly to take each trial and feed the first last 15 seconds (from -15 sec to 0 sec) into a transfomer\n",
    "\n",
    "So the data will be clipped below to only contain time points -15sec .. 0 sec\n",
    "\n",
    "Then we have 2 options: predict next neural time series time point VS. predicting time to lever pull. Here we only explore the next neural time series time point. There's a separate notebook for option 2.\n",
    "\n",
    "######################################################################\n",
    "\n",
    "############### PREDICT NEXT NEURAL TIME SERIES POINT ################\n",
    "\n",
    "######################################################################\n",
    "#### Step 1: predict next brain activity\n",
    "\n",
    "For each trial we take the time points and activity for each brain area and try to predict the next brain activity\n",
    "- input shape [time_points, brain_area] = [450, 16]\n",
    "- label: [time_points[1:], brain_area]\n",
    "\n",
    "We could even start with single brain area\n",
    "- input shape [time_points]   # for a single area this will look like a time series of length 15 x 30 = 450 time points\n",
    "                              #    for example:  [30.0, 125.0, -75.3, ... ]\n",
    "- label: [time_points[1:]   # so here we are predicting the input shifted by 1 [ 125.0, -75.3 ... ]\n",
    "\n",
    "If this works we can then think about all areas.\n",
    "\n",
    "Honestly, this is exactly what transformers are developed to do, so we shouldn't have to do too much work to adapt them. We can also smooth or bin the neural data as it's abit noisy.\n",
    "\n",
    "The major challenges are:\n",
    "\n",
    "1. Figure out how to convert the brain area activity - which is a float point - to a discretized value\n",
    "- I think for this I'd suggest taking the range of the neural activity e.g. -200 to + 200 and creating a \"vocabulary\" in increments of 10. That would give us a 40 token dictionary.\n",
    "\n",
    "2. It's not clear whether we should feed in snipeets of 15sec as explained above - or we need to randomize the location where we draw the snippets from so the transfomrer doesn't learn some average neural activity. Or maybe this is something that we want!?  Not clear.  In principle we should be able to feed in neural activity from any part of a recording (eg. 30minutes) and get a transformer to perform on this.\n",
    "- We also have this data, and perhaps we should provide it.\n",
    "- but for now, we're biasing ourselves by knowing the exact time of the lever pulls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############# LOAD DATA AND VISUALIZE AVERAGES #################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "###### TEST LOCANMF DATA ###########\n",
    "####################################\n",
    "data = np.load('/media/cat/4TBSSD/yuki/IA1/tif_files/IA1pm_Feb2_30Hz/IA1pm_Feb2_30Hz_locanmf.npz', allow_pickle=True)\n",
    "\n",
    "trial = data['temporal_trial']\n",
    "random = data['temporal_random']\n",
    "print (trial.shape, random.shape)\n",
    "\n",
    "names = data['names']\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "##### PREDICT SVM DECISION CHOICE SINGLE SESSION #####\n",
    "######################################################\n",
    "def predict_ROI_parallel(name,\n",
    "                         codes):\n",
    "    \n",
    "    # \n",
    "    svm = SVM.PredictSVMChoice()\n",
    "    svm.root_dir = data_dir\n",
    "    svm.random_flag = False  # shuffle data to show baseline\n",
    "\n",
    "    # window parameters\n",
    "    svm.window = 30              # prediction window, backwards in time in seconds\n",
    "    svm.lockout_window = 10      # time for locking out other pulls \n",
    "    svm.sliding_window = 30      # number of frames in sliding window\n",
    "    svm.lockout = False\n",
    "    svm.gpu_flag = False\n",
    "\n",
    "    # pca params\n",
    "    svm.pca_flag = True\n",
    "    svm.pca_var = 0.95  # this is default for now for nComp = 20\n",
    "\n",
    "    # svm parameters\n",
    "    svm.xvalidation = 10  # KFold xvalidation step\n",
    "    svm.data_split = 0.8  # split 80/20 data for training\n",
    "    svm.method = 'sigmoid'  # method used for computing SVM\n",
    "\n",
    "    # run-time parameters\n",
    "    svm.parallel = True\n",
    "    svm.n_cores = svm.xvalidation\n",
    "    svm.min_trials = 10\n",
    "    svm.overwrite = False\n",
    "\n",
    "\n",
    "    # session info\n",
    "    #session_ids = ['Mar1_', 'Mar2_', 'Mar3_', 'Feb29', 'Mar7_']\n",
    "    svm.session_id = 'all'\n",
    "    #svm.session_id = 'Feb9_'\n",
    "\n",
    "    #for name in names:\n",
    "    svm.animal_id = name\n",
    "\n",
    "    # \n",
    "    for code in codes:\n",
    "        svm.code = code\n",
    "\n",
    "        #\n",
    "        svm.predict_ROI()\n",
    "        \n",
    "        \n",
    "# select animal names\n",
    "names = ['IA1','IA2','IA3','IJ1','IJ2','AQ2'] # \"AR4\" and other datasets could work\n",
    "#names = ['IA1']\n",
    "\n",
    "# \n",
    "codes = ['Retrosplenial', 'barrel', 'limb', 'visual','motor']\n",
    "codes = ['limb, layer 1 - right', 'limb, layer 1 - left']\n",
    "\n",
    "#\n",
    "for name in names:\n",
    "    predict_ROI_parallel(name,codes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#################################################################\n",
    "#################################################################\n",
    "codes = ['left_paw','right_paw','jaw']\n",
    "\n",
    "fnames = [\n",
    "'/media/cat/4TBSSD/yuki/IA1/SVM_Scores/SVM_Scores_IA1pm_Feb5_30Hzjaw_trial_ROItimeCourses_15sec_Xvalid10_Slidewindow30.npz',\n",
    "'/media/cat/4TBSSD/yuki/IA1/SVM_Scores/SVM_Scores_IA1pm_Feb5_30Hzright_paw_trial_ROItimeCourses_15sec_Xvalid10_Slidewindow30.npz',\n",
    "'/media/cat/4TBSSD/yuki/IA1/SVM_Scores/SVM_Scores_IA1pm_Feb5_30Hzleft_paw_trial_ROItimeCourses_15sec_Xvalid10_Slidewindow30.npz'\n",
    "]\n",
    "\n",
    "for ctr,fname in enumerate(fnames):\n",
    "    data = np.load(fname)\n",
    "    acc = data['accuracy']\n",
    "    print (acc.shape)\n",
    "    acc = acc[:450]\n",
    "    t = np.arange(acc.shape[0])/30-14\n",
    "    plt.plot(t,acc.mean(1),label=codes[ctr])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/media/cat/4TBSSD/yuki/IA1/tif_files/IA1am_Mar4_30Hz/IA1am_Mar4_30Hz_locanmf.npz',allow_pickle=True)\n",
    "names = data['names']\n",
    "#print (names)\n",
    "for name in names:\n",
    "    if 'limb, layer 1 - right' in name:\n",
    "        print (name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
